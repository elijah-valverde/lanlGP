{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Proccess (GP) on M1 and S2 Site Data\n",
    "We wish to determine the seasonal and diurnal cycles of supermicron aerosols/bioaerosols. In this notebook we focus on the seasonal trends. We will split the data up by seasons and fit a GP on a subset of the data. Using a confidence interval, we will determine if the data indicates seasonal cycles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.special import kv, gamma\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interactive\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"2\"\n",
    "\n",
    "\n",
    "\n",
    "def data_import(path1, delimiter):\n",
    "    #locate file path and import data\n",
    "    if delimiter == 'none':\n",
    "        file1 = pd.read_csv(path1)\n",
    "    else:   \n",
    "        file1 = pd.read_csv(path1, delimiter=delimiter)\n",
    "    return file1\n",
    "\n",
    "def data_convert(file1, time_column_name: str):\n",
    "    #convert timestamps to datetime format\n",
    "    file1[time_column_name] = pd.to_datetime(file1[time_column_name])\n",
    "   \n",
    "    #handle missing values (NaN); fill with mean value\n",
    "    file1.fillna(file1.mean(), inplace=True)\n",
    "\n",
    "    return file1\n",
    "\n",
    "def data_frequency(file1, desired_frequency: str, time_column_name: str):\n",
    "    if desired_frequency == 'ten_minute':\n",
    "        file1 = file1.resample('10T', on=time_column_name).mean()\n",
    "    elif desired_frequency == '4_hourly':\n",
    "        file1 = file1.resample('4h', on=time_column_name).mean()\n",
    "    elif desired_frequency == 'hourly':\n",
    "        file1 = file1.resample('h', on=time_column_name).mean()\n",
    "    elif desired_frequency == 'twelve_hourly':\n",
    "        file1 = file1.resample('12h', on=time_column_name).mean()\n",
    "    elif desired_frequency == 'daily':\n",
    "        file1 = file1.resample('D', on=time_column_name).mean()\n",
    "\n",
    "    # Ensure the index is datetime\n",
    "    file1.index = pd.to_datetime(file1.index)\n",
    "    \n",
    "    # Reset the index and name it 'Time(UTC)'\n",
    "    file1.reset_index(inplace=True)\n",
    "    file1.rename(columns={file1.index.name: time_column_name}, inplace=True)\n",
    "\n",
    "    return file1\n",
    "\n",
    "\n",
    "def time_to_sincos(df):\n",
    "    sin_values = []\n",
    "    cos_values = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        sin_values.append(np.sin((2 * np.pi * i) / 365.25))\n",
    "        cos_values.append(np.cos((2 * np.pi * i) / 365.25))\n",
    "        \n",
    "    df['Time_sin'] = sin_values\n",
    "    df['Time_cos'] = cos_values\n",
    "    \n",
    "    return df\n",
    "\n",
    "#trim data to desired collumns\n",
    "def file_trim(file1, desired_collumns):\n",
    "    file1 = file1[desired_collumns]\n",
    "    return file1\n",
    "\n",
    "#separate data by seasons\n",
    "def data_split(file1, time_column_name: str):\n",
    "    winter = file1[(file1[time_column_name] >= '2022-12-21') & (file1[time_column_name] < '2023-03-20')]\n",
    "    spring = file1[(file1[time_column_name] >= '2023-03-20') & (file1[time_column_name] < '2023-06-21')]\n",
    "    summer = file1[(file1[time_column_name] >= '2022-06-21') & (file1[time_column_name] < '2022-09-23')]\n",
    "    autunm = file1[(file1[time_column_name] >= '2022-09-23') & (file1[time_column_name] < '2022-12-21')]\n",
    "    return winter, spring, summer, autunm\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S2 site data importing and modeling \n",
    "Here we import and handle all of the data. s2 first, split the varying frequencies and seasons, then M1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing s2 and m1 data sets\n",
    "s2_site_data= data_import(\"C:\\\\Users\\\\396760\\\\lanl\\\\data\\\\ARMSAILS2_cleaned.csv\", 'none')\n",
    "m1_site_data = data_import(\"C:\\\\Users\\\\396760\\\\lanl\\\\data\\\\ARMSAILM1_cleaned.csv\", 'none')\n",
    "\n",
    "#data conversion and handling for m1, s2 data\n",
    "s2_site_data, m1_site_data = data_convert(s2_site_data, 'Time(UTC)'), data_convert(m1_site_data, 'Time(UTC)')\n",
    "\n",
    "#defining collumns and imp feature variables\n",
    "collumns = ['Time(UTC)', 'sample_rh_pct', 'sample_temp_C', 'pm_1_ug_per_m3', 'Time_sin', 'Time_cos']\n",
    "collumns1 = ['Time(UTC)', 'sample_rh_pct', 'sample_temp_C', 'pm_25_ug_per_m3', 'Time_sin', 'Time_cos']\n",
    "features = ['sample_rh_pct', 'sample_temp_C', 'Time_sin', 'Time_cos']\n",
    "s2_target_pm1 = m1_target_pm1 = ['pm_1_ug_per_m3']\n",
    "s2_target_pm25 = m1_target_pm25 = ['pm_25_ug_per_m3']\n",
    "s2_target_pm10 = m1_target_pm10 = ['pm_10_ug_per_m3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining datasets of differing frequencies in the following order : daily, 12 hourly, 4 hourly and hourly, \n",
    "s2_site_daily, m1_site_daily = data_frequency(s2_site_data, 'daily', 'Time(UTC)'), data_frequency(m1_site_data, 'daily', 'Time(UTC)')\n",
    "s2_site_12hourly, m1_site_12hourly = data_frequency(s2_site_data, 'twelve_hourly', 'Time(UTC)'), data_frequency(m1_site_data, 'twelve_hourly', 'Time(UTC)')\n",
    "s2_site_4hourly, m1_site_4hourly = data_frequency(s2_site_data, '4_hourly', 'Time(UTC)'), data_frequency(m1_site_data, '4_hourly', 'Time(UTC)')\n",
    "s2_site_hourly, m1_site_hourly = data_frequency(s2_site_data, 'hourly', 'Time(UTC)'), data_frequency(m1_site_data, 'hourly', 'Time(UTC)')\n",
    "\n",
    "#time to sin cos conversion\n",
    "s2_site_daily, m1_site_daily = time_to_sincos(s2_site_daily), time_to_sincos(m1_site_daily)\n",
    "s2_site_12hourly, m1_site_12hourly = time_to_sincos(s2_site_12hourly), time_to_sincos(m1_site_12hourly)\n",
    "s2_site_4hourly, m1_site_4hourly = time_to_sincos(s2_site_4hourly), time_to_sincos(m1_site_4hourly)\n",
    "s2_site_hourly, m1_site_hourly = time_to_sincos(s2_site_hourly), time_to_sincos(m1_site_hourly)\n",
    "\n",
    "#trimming data to desired collumns\n",
    "s2_site_daily, m1_site_daily = file_trim(s2_site_daily, collumns), file_trim(m1_site_daily, collumns)\n",
    "s2_site_12hourly, m1_site_12hourly = file_trim(s2_site_12hourly, collumns), file_trim(m1_site_12hourly, collumns)\n",
    "s2_site_4hourly, m1_site_4hourly = file_trim(s2_site_4hourly, collumns), file_trim(m1_site_4hourly, collumns)\n",
    "s2_site_hourly, m1_site_hourly = file_trim(s2_site_hourly, collumns), file_trim(m1_site_hourly, collumns)\n",
    "\n",
    "#splitting data by seasons\n",
    "\n",
    "#daily\n",
    "s2_winter_daily, s2_spring_daily, s2_summer_daily, s2_autunm_daily = data_split(s2_site_daily, 'Time(UTC)')\n",
    "m1_winter_daily, m1_spring_daily, m1_summer_daily, m1_autunm_daily = data_split(m1_site_daily, 'Time(UTC)')\n",
    "#12 hourly\n",
    "s2_winter_12hourly, s2_spring_12hourly, s2_summer_12hourly, s2_autunm_12hourly = data_split(s2_site_12hourly, 'Time(UTC)')\n",
    "m1_winter_12hourly, m1_spring_12hourly, m1_summer_12hourly, m1_autunm_12hourly = data_split(m1_site_12hourly, 'Time(UTC)')\n",
    "#4 hourly\n",
    "s2_winter_4hourly, s2_spring_4hourly, s2_summer_4hourly, s2_autunm_4hourly = data_split(s2_site_4hourly, 'Time(UTC)')\n",
    "m1_winter_4hourly, m1_spring_4hourly, m1_summer_4hourly, m1_autunm_4hourly = data_split(m1_site_4hourly, 'Time(UTC)')\n",
    "#hourly\n",
    "s2_winter_hourly, s2_spring_hourly, s2_summer_hourly, s2_autunm_hourly = data_split(s2_site_hourly, 'Time(UTC)')\n",
    "m1_winter_hourly, m1_spring_hourly, m1_summer_hourly, m1_autunm_hourly = data_split(m1_site_hourly, 'Time(UTC)')\n",
    "\n",
    "#plots for s2 data sites at varying frequencies (PM1)\n",
    "\n",
    "#daily\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(s2_winter_daily['Time(UTC)'], s2_winter_daily['pm_1_ug_per_m3'], label='Winter')\n",
    "plt.plot(s2_spring_daily['Time(UTC)'], s2_spring_daily['pm_1_ug_per_m3'], label='Spring')\n",
    "plt.plot(s2_summer_daily['Time(UTC)'], s2_summer_daily['pm_1_ug_per_m3'], label='Summer')\n",
    "plt.plot(s2_autunm_daily['Time(UTC)'], s2_autunm_daily['pm_1_ug_per_m3'], label='Autunm')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#12 hourly\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(s2_winter_12hourly['Time(UTC)'], s2_winter_12hourly['pm_1_ug_per_m3'], label='Winter')\n",
    "plt.plot(s2_spring_12hourly['Time(UTC)'], s2_spring_12hourly['pm_1_ug_per_m3'], label='Spring')\n",
    "plt.plot(s2_summer_12hourly['Time(UTC)'], s2_summer_12hourly['pm_1_ug_per_m3'], label='Summer')\n",
    "plt.plot(s2_autunm_12hourly['Time(UTC)'], s2_autunm_12hourly['pm_1_ug_per_m3'], label='Autunm')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#4 hourly\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(s2_winter_4hourly['Time(UTC)'], s2_winter_4hourly['pm_1_ug_per_m3'], label='Winter')\n",
    "plt.plot(s2_spring_4hourly['Time(UTC)'], s2_spring_4hourly['pm_1_ug_per_m3'], label='Spring')\n",
    "plt.plot(s2_summer_4hourly['Time(UTC)'], s2_summer_4hourly['pm_1_ug_per_m3'], label='Summer')\n",
    "plt.plot(s2_autunm_4hourly['Time(UTC)'], s2_autunm_4hourly['pm_1_ug_per_m3'], label='Autunm')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#hourly\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(s2_winter_hourly['Time(UTC)'], s2_winter_hourly['pm_1_ug_per_m3'], label='Winter')\n",
    "plt.plot(s2_spring_hourly['Time(UTC)'], s2_spring_hourly['pm_1_ug_per_m3'], label='Spring')\n",
    "plt.plot(s2_summer_hourly['Time(UTC)'], s2_summer_hourly['pm_1_ug_per_m3'], label='Summer')\n",
    "plt.plot(s2_autunm_hourly['Time(UTC)'], s2_autunm_hourly['pm_1_ug_per_m3'], label='Autunm')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualizing our choice of kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_kernel_function_space(kernel, x_range, n_functions, **kernel_params):\n",
    "    # Create a grid of x values\n",
    "    X = np.atleast_2d(x_range).T\n",
    "\n",
    "    # Compute the kernel matrix\n",
    "    K = kernel(X, X, **kernel_params)\n",
    "\n",
    "    # Clear the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Generate functions\n",
    "    for _ in range(n_functions):\n",
    "        # Draw samples from a multivariate normal distribution\n",
    "        f = multivariate_normal.rvs(mean=10*np.ones(X.shape[0]), cov=K)\n",
    "        \n",
    "        # Plot the function\n",
    "        plt.plot(x_range, f)\n",
    "\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Function Value')\n",
    "    plt.title(f'Functions Sampled from {kernel.__name__}')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def white_noise_kernel(x1, x2, variance=2.0):\n",
    "    return variance * np.eye(len(x1))\n",
    "\n",
    "def rbf_kernel(x1, x2, length_scale=1.0, variance=1.0):\n",
    "    # Compute the pairwise squared distances between the inputs\n",
    "    sq_dists = cdist(x1, x2, 'sqeuclidean')\n",
    "    \n",
    "    # Compute the kernel\n",
    "    return variance * np.exp(-0.5 * sq_dists / length_scale**2)\n",
    "\n",
    "def periodic_kernel(x1, x2, length_scale=1.0, variance=1.0, period=1.0):\n",
    "    # Compute the pairwise squared distances between the inputs\n",
    "    sq_dists = cdist(x1, x2, 'sqeuclidean')\n",
    "    \n",
    "    # Compute the kernel\n",
    "    return variance * np.exp(-2 * np.sin(np.pi * np.sqrt(sq_dists) / period)**2 / length_scale**2)\n",
    "\n",
    "def matern_kernel(x, x_star, length_scale=1.0, nu=0.5, variance=1.0):\n",
    "    dists = cdist(x / length_scale, x_star / length_scale, metric='euclidean')\n",
    "    \n",
    "    if nu == 0.5:\n",
    "        K = np.exp(-dists)\n",
    "    elif nu == 1.5:\n",
    "        sqrt3 = np.sqrt(3)\n",
    "        K = (1.0 + sqrt3 * dists) * np.exp(-sqrt3 * dists)\n",
    "    elif nu == 2.5:\n",
    "        sqrt5 = np.sqrt(5)\n",
    "        K = (1.0 + sqrt5 * dists + (5.0 / 3.0) * (dists ** 2)) * np.exp(-sqrt5 * dists)\n",
    "\n",
    "    return variance * K\n",
    "\n",
    "def sum_kernel(x1, x2, variance, length_scale, nu):\n",
    "    return white_noise_kernel(x1, x2, variance=variance) + matern_kernel(x1, x2, variance=variance, length_scale=length_scale, nu=nu) + periodic_kernel(x1, x2, variance=variance, length_scale=length_scale, period=period)\n",
    "\n",
    "x_space = np.linspace(0, 10, 100)\n",
    "num_of_functions = 3\n",
    "\n",
    "# Create sliders for kernel parameters\n",
    "def plot_white_noise_kernel(variance):\n",
    "    visualize_kernel_function_space(white_noise_kernel, x_space, num_of_functions, variance=variance)\n",
    "\n",
    "def plot_rbf_kernel(length_scale, variance):\n",
    "    visualize_kernel_function_space(rbf_kernel, x_space, num_of_functions, length_scale=length_scale, variance=variance)\n",
    "\n",
    "def plot_periodic_kernel(length_scale, variance, period):\n",
    "    visualize_kernel_function_space(periodic_kernel, x_space, num_of_functions, length_scale=length_scale, variance=variance, period=period)\n",
    "\n",
    "def plot_matern_kernel(length_scale, nu, variance):\n",
    "    visualize_kernel_function_space(matern_kernel, x_space, num_of_functions, length_scale=length_scale, nu=nu, variance=variance)\n",
    "\n",
    "def plot_sum_kernel(variance, length_scale, nu, period):\n",
    "    visualize_kernel_function_space(sum_kernel, x_space, num_of_functions, variance=variance, length_scale=length_scale, nu=nu, period=period)\n",
    "\n",
    "# Create interactive widgets\n",
    "interactive_plot_white_noise = interactive(plot_white_noise_kernel, variance=widgets.FloatSlider(min=0.1, max=10.0, step=0.1, value=2.0))\n",
    "interactive_plot_rbf = interactive(plot_rbf_kernel, length_scale=widgets.FloatSlider(min=0.1, max=10.0, step=0.1, value=1.0), variance=widgets.FloatSlider(min=0.1, max=10.0, step=0.1, value=1.0))\n",
    "interactive_plot_periodic = interactive(plot_periodic_kernel, length_scale=widgets.FloatSlider(min=0.1, max=10.0, step=0.1, value=1.0), variance=widgets.FloatSlider(min=0.1, max=10.0, step=0.1, value=1.0), period=widgets.FloatSlider(min=0.1, max=10.0, step=0.1, value=1.0))\n",
    "interactive_plot_matern = interactive(plot_matern_kernel, length_scale=widgets.FloatSlider(min=0.1, max=10.0, step=0.1, value=1.0), nu=widgets.FloatSlider(min=0.5, max=2.5, step=1.0, value=0.5), variance=widgets.FloatSlider(min=0.1, max=10.0, step=0.1, value=1.0))\n",
    "interactive_plot_sum = interactive(plot_sum_kernel, variance=widgets.FloatSlider(min=0.1, max=10.0, step=0.1, value=1.0), length_scale=widgets.FloatSlider(min=0.1, max=10.0, step=0.1, value=1.0), nu=widgets.FloatSlider(min=0.5, max=2.5, step=1.0, value=0.5), period=widgets.FloatSlider(min=0.1, max=10.0, step=0.1, value=1.0))\n",
    "display(interactive_plot_white_noise)\n",
    "display(interactive_plot_rbf)\n",
    "display(interactive_plot_periodic)\n",
    "display(interactive_plot_matern)\n",
    "display(interactive_plot_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def covariance_matrix(x, x_star, kernel, **kernel_params):\n",
    "    return kernel(x, x_star, **kernel_params)\n",
    "\n",
    "def run_gp_regression(X, y, X_star, kernel, **kernel_params):\n",
    "\n",
    "    # Compute the covariance matrices\n",
    "    K = covariance_matrix(X, X, kernel, **kernel_params)\n",
    "    K_star = covariance_matrix(X, X_star, kernel, **kernel_params)\n",
    "    K_star_star = covariance_matrix(X_star, X_star, kernel, **kernel_params)\n",
    "    \n",
    "    # Compute the Cholesky decomposition of K\n",
    "    L = np.linalg.cholesky(K + 1e-6 * np.eye(len(X)))\n",
    "    \n",
    "    # Compute the mean of the posterior predictive distribution\n",
    "    alpha = np.linalg.solve(L.T, np.linalg.solve(L, y))\n",
    "    f_star_mean = K_star.T @ alpha\n",
    "    \n",
    "    # Compute the variance of the posterior predictive distribution\n",
    "    v = np.linalg.solve(L, K_star)\n",
    "    f_star_var = K_star_star - v.T @ v\n",
    "    \n",
    "    return f_star_mean, f_star_var\n",
    "\n",
    "def RMSE_calc(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def plot_gp(X, y, X_star, y_star, f_star_mean, f_star_var, kernel_name):\n",
    "    # Plot the training data\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(X, y, color='black', label='Training Data')\n",
    "    \n",
    "    # Plot the true function\n",
    "    plt.plot(X_star, y_star, color='blue', label='True Function')\n",
    "    \n",
    "    # Plot the mean of the posterior predictive distribution\n",
    "    plt.plot(X_star, f_star_mean, color='red', label='Mean of Posterior Predictive')\n",
    "    \n",
    "    # Plot the 95% confidence interval\n",
    "    plt.fill_between(X_star, f_star_mean - 1.96 * np.sqrt(np.diag(f_star_var)), f_star_mean + 1.96 * np.sqrt(np.diag(f_star_var)), color='red', alpha=0.2, label='95% Confidence Interval')\n",
    "    \n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.title(f'Gaussian Process Regression with {kernel_name}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.70989333e+01  1.08222097e+01  9.86146248e-01 -1.65878199e-01]\n",
      " [ 4.22430750e+01  1.12089618e+01  9.83146974e-01 -1.82816925e-01]\n",
      " [ 3.26547451e+01  1.28113882e+01  9.79856770e-01 -1.99701553e-01]\n",
      " [ 2.84274167e+01  1.40744569e+01  9.76276611e-01 -2.16527085e-01]\n",
      " [ 3.59275500e+01  1.38221729e+01  9.72407556e-01 -2.33288544e-01]\n",
      " [ 4.71497146e+01  1.23835257e+01  9.68250750e-01 -2.49980969e-01]\n",
      " [ 4.81332090e+01  1.16796097e+01  9.63807423e-01 -2.66599421e-01]\n",
      " [ 6.39657646e+01  9.23182569e+00  9.59078890e-01 -2.83138981e-01]\n",
      " [ 7.77019396e+01  5.75215139e+00  9.54066550e-01 -2.99594756e-01]\n",
      " [ 8.10055417e+01  5.83488889e+00  9.48771886e-01 -3.15961877e-01]\n",
      " [ 7.81243340e+01  5.61884236e+00  9.43196466e-01 -3.32235499e-01]\n",
      " [ 6.05938292e+01  8.03130972e+00  9.37341938e-01 -3.48410807e-01]\n",
      " [ 4.96280486e+01  7.91240625e+00  9.31210036e-01 -3.64483015e-01]\n",
      " [ 5.76202236e+01  8.51429167e+00  9.24802574e-01 -3.80447366e-01]\n",
      " [ 5.16488896e+01  9.13146042e+00  9.18121448e-01 -3.96299137e-01]\n",
      " [ 4.24527868e+01  8.42114097e+00  9.11168635e-01 -4.12033637e-01]\n",
      " [ 4.35623903e+01  8.17160347e+00  9.03946193e-01 -4.27646209e-01]\n",
      " [ 4.68957688e+01  7.56294028e+00  8.96456258e-01 -4.43132234e-01]\n",
      " [ 5.33431590e+01  5.67719282e+00  8.88701048e-01 -4.58487129e-01]\n",
      " [ 5.02266833e+01  5.51667984e+00  8.80682856e-01 -4.73706350e-01]\n",
      " [ 5.02266833e+01  5.51667984e+00  8.72404057e-01 -4.88785394e-01]\n",
      " [ 5.02266833e+01  5.51667984e+00  8.63867099e-01 -5.03719799e-01]\n",
      " [ 5.02266833e+01  5.51667984e+00  8.55074509e-01 -5.18505144e-01]\n",
      " [ 5.02266833e+01  5.51667984e+00  8.46028888e-01 -5.33137056e-01]\n",
      " [ 5.02266833e+01  5.51667984e+00  8.36732914e-01 -5.47611204e-01]\n",
      " [ 5.02266833e+01  5.51667984e+00  8.27189337e-01 -5.61923305e-01]\n",
      " [ 5.02266833e+01  5.51667984e+00  8.17400982e-01 -5.76069123e-01]\n",
      " [ 3.83648832e+01  9.20415312e+00  8.07370744e-01 -5.90044474e-01]\n",
      " [ 2.94737243e+01  7.80025347e+00  7.97101593e-01 -6.03845221e-01]\n",
      " [ 3.88549771e+01  6.48251806e+00  7.86596566e-01 -6.17467280e-01]\n",
      " [ 5.88890764e+01  3.03406181e+00  7.75858773e-01 -6.30906621e-01]\n",
      " [ 6.08263326e+01 -5.55331319e+00  7.64891390e-01 -6.44159267e-01]\n",
      " [ 6.15987451e+01 -4.07586319e+00  7.53697664e-01 -6.57221295e-01]\n",
      " [ 7.48828444e+01 -3.07000000e-02  7.42280907e-01 -6.70088841e-01]\n",
      " [ 6.45237104e+01 -1.06165417e+00  7.30644497e-01 -6.82758097e-01]\n",
      " [ 5.87641632e+01 -1.78188889e+00  7.18791877e-01 -6.95225314e-01]\n",
      " [ 4.27464875e+01  5.57597222e-01  7.06726556e-01 -7.07486802e-01]\n",
      " [ 3.74517576e+01  1.93266319e+00  6.94452102e-01 -7.19538934e-01]\n",
      " [ 3.91634444e+01  1.96527361e+00  6.81972149e-01 -7.31378143e-01]\n",
      " [ 3.86312424e+01  3.57737569e+00  6.69290390e-01 -7.43000925e-01]\n",
      " [ 3.59210243e+01  4.51589167e+00  6.56410576e-01 -7.54403841e-01]\n",
      " [ 6.17963806e+01  5.38193750e-01  6.43336520e-01 -7.65583517e-01]\n",
      " [ 6.36218819e+01 -4.75132153e+00  6.30072091e-01 -7.76536644e-01]\n",
      " [ 7.26347319e+01 -4.06611042e+00  6.16621213e-01 -7.87259982e-01]\n",
      " [ 6.97748681e+01  6.50568056e-01  6.02987867e-01 -7.97750357e-01]\n",
      " [ 5.27940653e+01  5.18227917e+00  5.89176087e-01 -8.08004665e-01]\n",
      " [ 4.42447213e+01  3.88762136e+00  5.75189961e-01 -8.18019871e-01]\n",
      " [ 5.02266833e+01  5.51667984e+00  5.61033626e-01 -8.27793012e-01]\n",
      " [ 5.02266833e+01  5.51667984e+00  5.46711273e-01 -8.37321195e-01]\n",
      " [ 5.02266833e+01  5.51667984e+00  5.32227139e-01 -8.46601602e-01]\n",
      " [ 5.02266833e+01  5.51667984e+00  5.17585510e-01 -8.55631486e-01]\n",
      " [ 5.02266833e+01  5.51667984e+00  5.02790720e-01 -8.64408174e-01]\n",
      " [ 5.02266833e+01  5.51667984e+00  4.87847145e-01 -8.72929071e-01]\n",
      " [ 4.63478415e+01  3.51783732e+00  4.72759209e-01 -8.81191653e-01]\n",
      " [ 4.50234243e+01  1.66518063e+00  4.57531376e-01 -8.89193477e-01]\n",
      " [ 5.45417220e+01 -6.81622661e+00  4.42168152e-01 -8.96932174e-01]\n",
      " [ 5.49632444e+01 -6.66599028e+00  4.26674083e-01 -9.04405455e-01]\n",
      " [ 4.80235627e+01 -2.85004090e+00  4.11053755e-01 -9.11611107e-01]\n",
      " [ 3.34589465e+01 -3.94166736e+00  3.95311789e-01 -9.18546999e-01]\n",
      " [ 2.59645222e+01 -9.55472917e-01  3.79452844e-01 -9.25211078e-01]\n",
      " [ 2.22061847e+01 -7.63109028e-01  3.63481612e-01 -9.31601373e-01]\n",
      " [ 3.00419097e+01 -3.73525139e+00  3.47402821e-01 -9.37715991e-01]\n",
      " [ 4.71384333e+01 -4.55273611e+00  3.31221228e-01 -9.43553124e-01]\n",
      " [ 3.85388910e+01 -1.20565000e+00  3.14941621e-01 -9.49111045e-01]\n",
      " [ 4.00616917e+01  6.58657639e-01  2.98568817e-01 -9.54388108e-01]\n",
      " [ 5.98771299e+01 -2.97449931e+00  2.82107663e-01 -9.59382753e-01]\n",
      " [ 3.98727160e+01 -3.63254167e+00  2.65563028e-01 -9.64093501e-01]\n",
      " [ 7.24768406e+01 -8.32032611e+00  2.48939809e-01 -9.68518958e-01]\n",
      " [ 4.63671355e+01  4.05735056e+00  2.32242924e-01 -9.72657815e-01]\n",
      " [ 5.05395833e+01 -1.49581458e+00  2.15477315e-01 -9.76508846e-01]\n",
      " [ 6.38022056e+01 -1.75219931e+00  1.98647943e-01 -9.80070913e-01]\n",
      " [ 6.58531201e+01 -4.88460833e+00  1.81759788e-01 -9.83342961e-01]\n",
      " [ 7.12028486e+01  2.42861111e-01  1.64817847e-01 -9.86324023e-01]\n",
      " [ 7.08400944e+01  3.41412500e-01  1.47827133e-01 -9.89013215e-01]\n",
      " [ 7.16652111e+01 -2.46025069e+00  1.30792676e-01 -9.91409742e-01]\n",
      " [ 6.99702257e+01 -2.31452222e+00  1.13719515e-01 -9.93512895e-01]\n",
      " [ 6.77356014e+01 -4.73298125e+00  9.66127019e-02 -9.95322051e-01]\n",
      " [ 6.02131264e+01 -8.80031875e+00  7.94772999e-02 -9.96836676e-01]\n",
      " [ 5.29305979e+01 -5.32200278e+00  6.23183794e-02 -9.98056321e-01]\n",
      " [ 3.77179243e+01 -2.03006875e+00  4.51410178e-02 -9.98980625e-01]\n",
      " [ 4.53470838e+01 -2.00964397e+00  2.79502982e-02 -9.99609314e-01]\n",
      " [ 6.54070681e+01 -1.01401312e+01  1.07513078e-02 -9.99942203e-01]\n",
      " [ 6.24380961e+01 -1.02847393e+01 -6.45086420e-03 -9.99979193e-01]\n",
      " [ 5.15844994e+01 -8.57783897e-01 -2.36511272e-02 -9.99720273e-01]\n",
      " [ 4.53540669e+01  1.05552420e+00 -4.08443915e-02 -9.99165520e-01]\n",
      " [ 4.24615045e+01  3.32641178e+00 -5.80255693e-02 -9.98315097e-01]\n",
      " [ 4.40388631e+01  5.14269613e-01 -7.51895764e-02 -9.97169257e-01]\n",
      " [ 3.52756222e+01 -7.52970625e+00 -9.23313337e-02 -9.95728339e-01]\n",
      " [ 4.90114785e+01 -7.76637847e+00 -1.09445769e-01 -9.93992768e-01]]\n"
     ]
    }
   ],
   "source": [
    "#Pick a random subset of the s2_autumn_daily data\n",
    "X = s2_autunm_daily[features].values\n",
    "y = s2_autunm_daily['pm_1_ug_per_m3'].values\n",
    "X, y = np.array(X), y.reshape(-1, 1)\n",
    "\n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysisV1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
